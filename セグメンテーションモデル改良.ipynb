{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nDFs1SP4yLJp"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zyGJuOuayOZL"},"outputs":[],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p46jEAIDyOW1"},"outputs":[],"source":["from glob import glob\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.base import SegmentationHead\n","import segmentation_models_pytorch.utils.metrics as smp_metrics\n","import segmentation_models_pytorch.utils.train as smp_train\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6809y6IyOUn"},"outputs":[],"source":["# 今回の学習で必要になる処理を入れたDataset\n","class MyDataset(Dataset):\n","    def __init__(self, imgs, masks, transform):\n","        \"\"\"\n","        imgs : 画像が入ったlist\n","        masks : 正解マスクが入ったlist\n","        transform : 画像やマスクに前処理を行う関数\n","        \"\"\"\n","        self.imgs = imgs\n","        self.masks = masks\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    # 処理を行う部分\n","    def __getitem__(self, idx):\n","        img = self.imgs[idx]\n","        mask = (self.masks[idx] > 0).astype(float)\n","\n","        # 画像とマスクに前処理を実施\n","        sample = self.transform(image=img, mask=mask)\n","        img, mask = sample['image'], sample['mask']\n","\n","        return img, mask.unsqueeze(0) # maskは3チャンネルである必要あり（class, H, W）\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhHDNQgmmX39"},"outputs":[],"source":["# bce lossとdice lossを組み合わせたloss\n","class BCE_Dice_Loss(smp.utils.base.Loss):\n","    def __init__(self, alpha, **kwargs):\n","        # loss = alpha * bce + (1 - alpha) * dice_loss\n","        super().__init__(**kwargs)\n","        self.bce = nn.BCEWithLogitsLoss()\n","        self.dice_loss = smp.losses.DiceLoss(mode=\"binary\",\n","                                             log_loss=True, from_logits=True)\n","        self.alpha = alpha\n","\n","    def forward(self, y_pr, y_gt):\n","        loss = self.alpha * self.bce(y_pr, y_gt.float()) \\\n","             + (1 - self.alpha) * self.dice_loss(y_pr, y_gt.float())\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gUAA4chAPZ18"},"outputs":[],"source":["# 前処理の定義\n","# Composeを使用すると複数の処理を一気に行うことができる\n","\n","# 訓練用\n","train_transform = A.Compose([\n","    A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=10, p=0.5), # ランダムで画像を拡大縮小+回転\n","    A.Resize(640,640),\n","    A.HorizontalFlip(p=0.5), #ランダムで画像を水平反転\n","    A.VerticalFlip(p=0.5), #ランダムで画像を垂直反転\n","    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),  # ランダムで画像の明るさとコントラストを変える\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2(), #numpy arrayをpytorchで使用するTensorに変換\n","])\n","\n","# 推論用\n","val_transform = A.Compose([\n","    A.Resize(640,640),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2()\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RwpK5h0KS00"},"outputs":[],"source":["# data loaderを作成する関数\n","def make_dataloader(imgs, masks, transforms, batch_size, shuffle=True):\n","    dataset = MyDataset(imgs, masks, transforms)\n","    loader = DataLoader(dataset, batch_size=batch_size,\n","                        drop_last=False, shuffle=shuffle, num_workers=2)\n","\n","    return loader\n","\n","# 学習に使用するモデル類を作成する関数\n","def make_model(device):\n","\n","    model = smp.Unet(\n","        encoder_name=\"tu-convnext_tiny.fb_in1k\", #timmのモデルを使う際は先頭にtu-をつける\n","        encoder_weights=\"imagenet\",\n","        in_channels=3,\n","        classes=1,\n","        encoder_depth=4,\n","        decoder_attention_type=\"scse\", #追加モジュール\n","        decoder_channels=[256, 128, 64, 32], #convnextはエンコーダの出力数が4個なのでデコーダの調整が必要\n","    )\n","    #convnextを用いると出力サイズが元の1/2になっているので、headの部分だけ置き換えてあげる\n","    model.segmentation_head = SegmentationHead(in_channels=32, out_channels=1, upsampling=2)  # サイズが2倍になる\n","\n","\n","    # 損失関数\n","    loss = BCE_Dice_Loss(0.5) #BCE + Dice lossを使用\n","\n","    # 評価関数（今回はIoUを使用）\n","    metrics = [\n","        smp_metrics.IoU(threshold=0.5, activation=\"sigmoid\"),\n","    ]\n","\n","    # 最適化関数（今回はAdamWを使用）\n","    optimizer = optim.AdamW(params=model.parameters(), lr=5e-5) #学習率を小さめに設定\n","\n","    # smpに用意されているシンプルなループ用クラス（train用）\n","    train_epoch = smp_train.TrainEpoch(\n","        model,\n","        loss=loss,\n","        metrics=metrics,\n","        optimizer=optimizer,\n","        device=device,\n","        verbose=True,\n","    )\n","\n","    # smpに用意されているシンプルなループ用クラス（valid用）\n","    valid_epoch = smp_train.ValidEpoch(\n","        model,\n","        loss=loss,\n","        metrics=metrics,\n","        device=device,\n","        verbose=True,\n","    )\n","\n","    return model, train_epoch, valid_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoKaxTuDdx_f"},"outputs":[],"source":["# テストデータの評価時に使用するループ処理を行う関数 TTAを行って予測\n","def test_loop(model, data_loader, metric, device):\n","    \"\"\"\n","    model : 学習済みのモデル\n","    data_loader : テストのデータローダー\n","    metric : 評価関数（今回はIoU）\n","    device : GPU or CPU\n","    \"\"\"\n","\n","    metric_list = [] # テスト画像のIoUの結果を保持するためのリスト\n","    for x, y in data_loader:\n","        # TTA用の画像を用意する\n","        # 通常画像、垂直反転画像、水平反転画像の3種類を作成し予測を行う\n","        x = torch.cat([x, torch.flip(x, [-2]), torch.flip(x, [-1])], 0)\n","        x, y = x.to(device), y.to(device)\n","        with torch.no_grad():\n","            y_pred = torch.sigmoid(model(x)) #事前にsigmoid\n","        # 作成した画像の内、垂直反転画像、水平反転画像を元に戻して3つの予測の平均を取る\n","        y_pred = y_pred[0:1] + torch.flip(y_pred[1:2], [-2]) + torch.flip(y_pred[2:3], [-1])\n","        y_pred = y_pred / 3.0\n","        # IoU計算\n","        metric_value = metric(y_pred, y).cpu().detach().numpy()\n","        metric_list.append(float(metric_value))\n","\n","    return metric_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKqsAmNEIIZa"},"outputs":[],"source":["img_path = sorted(glob(\"/content/drive/MyDrive/止まれセグメンテーション/dataset/image/*.jpg\"))\n","img = [cv2.imread(i)[..., [2,1,0]] for i in img_path] # BGR→RGBで読み込み\n","\n","mask_path = sorted(glob(\"/content/drive/MyDrive/止まれセグメンテーション/dataset/mask/*.png\"))\n","mask = [cv2.imread(i, 0) for i in mask_path]\n","\n","num_tomare = len(img_path) // 3 # 「止まれ」の組数\n","idxes = list(range(num_tomare)) # 分割に使用するため事前にインデックスのリストを用意\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1704443587639,"user":{"displayName":"髙木優介","userId":"16066762327054986394"},"user_tz":-540},"id":"URv0oSVQMXj7","outputId":"5fc8ecbb-7748-432a-b70d-fd53b3478219"},"outputs":[{"data":{"text/plain":["[[0, 6, 12, 18, 24],\n"," [1, 7, 13, 19, 25],\n"," [2, 8, 14, 20, 26],\n"," [3, 9, 15, 21, 27],\n"," [4, 10, 16, 22, 28],\n"," [5, 11, 17, 23, 29]]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# fold数は6\n","n_splits = 6\n","\n","# 「止まれ」の組を6等分する\n","fold_idxes = []\n","for i in range(n_splits):\n","    fold = [idxes[j] for j in range(i, num_tomare, n_splits)]\n","    fold_idxes.append(fold)\n","fold_idxes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704443589855,"user":{"displayName":"髙木優介","userId":"16066762327054986394"},"user_tz":-540},"id":"60ggsh32PuD7","outputId":"52f7c320-e04d-48dd-ae5d-964d94f84a6f"},"outputs":[{"data":{"text/plain":["[[0, 1, 2, 3, 4, 5],\n"," [1, 2, 3, 4, 5, 0],\n"," [2, 3, 4, 5, 0, 1],\n"," [3, 4, 5, 0, 1, 2],\n"," [4, 5, 0, 1, 2, 3],\n"," [5, 0, 1, 2, 3, 4]]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# 全ての分割が評価に使用されるように順繰りにしたインデックスを用意\n","folds = [[i%n_splits for i in range(j, j+n_splits)] for j in range(n_splits)]\n","folds"]},{"cell_type":"markdown","metadata":{"id":"WJJ7flSLbs-I"},"source":["fold 0 は folds[0]を使用し、fold_idxes[[0,1,2,3]]の「止まれ」を学習に、fold_idxes[4]をvalidationに、fold_idxes[5]をテストに使用する。\n","\n","同様に、\n","fold 1 は folds[1]を使用し、fold_idxes[[1,2,3,4]]の「止まれ」を学習に、fold_idxes[5]をvalidationに、fold_idxes[0]をテストに使用する。\n","\n","これをfold 0 〜 5の6回行う。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D8fVLBwFKNLI"},"outputs":[],"source":["# バッチサイズは5\n","batch_size = 5\n","# 学習epoch数 Data augmentationを追加したので長めに学習\n","n_epoch = 40\n","\n","# 使用デバイスの設定（今回はcudaが設定される）\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","test_iou_list = [] # 各foldで行われたテストの評価結果を保持\n","\n","# 順番にfoldの学習・評価を行う\n","for enum, fold in enumerate(folds):\n","    print(f\"fold : {enum+1}\")\n","\n","    train_img, train_mask = [], []\n","\n","    # foldのリストの最初の4つは訓練データ\n","    for f in fold[:4]:\n","        img_tmp = [img[i*3 + j] for i in fold_idxes[f] for j in range(3)]\n","        mask_tmp = [mask[i*3 + j] for i in fold_idxes[f] for j in range(3)]\n","\n","        train_img += img_tmp\n","        train_mask += mask_tmp\n","\n","    # 5番目はvalid\n","    valid_img = [img[i*3 + j] for i in fold_idxes[fold[-2]] for j in range(3)]\n","    valid_mask = [mask[i*3 + j] for i in fold_idxes[fold[-2]] for j in range(3)]\n","    # 6番目はtest\n","    test_img = [img[i*3 + j] for i in fold_idxes[fold[-1]] for j in range(3)]\n","    test_mask = [mask[i*3 + j] for i in fold_idxes[fold[-1]] for j in range(3)]\n","\n","    # data loaderを作成\n","    train_loader = make_dataloader(train_img, train_mask, train_transform,\n","                                   batch_size, True)\n","    valid_loader = make_dataloader(valid_img, valid_mask, val_transform,\n","                                   batch_size, False)\n","    test_loader = make_dataloader(test_img, test_mask, val_transform,\n","                                  1, False) # テストの評価はbatch_sizeを1に\n","\n","    model, train_epoch, valid_epoch = make_model(device)\n","\n","    # 学習ループの実行\n","    max_score = 0 # ベストのスコアを保持する用\n","    # モデルの保存名(適宜名前を変えてください)\n","    model_save_path = f\"/content/drive/MyDrive/止まれセグメンテーション/best_model_{enum}_v2.pth\"\n","\n","    # n_epoch分学習ループを回す\n","    for e in range(0, n_epoch):\n","        print(f'Epoch: {e+1}')\n","\n","        # 学習\n","        _ = train_epoch.run(train_loader)\n","\n","        # 評価\n","        valid_logs = valid_epoch.run(valid_loader)\n","\n","        # もしvalidのIoUスコアが今までの最大値よりも大きかったらモデルの保存\n","        if max_score < valid_logs['iou_score']:\n","            max_score = valid_logs['iou_score']\n","            torch.save(model.state_dict(), model_save_path)\n","            print('Model saved!')\n","\n","    # 保存したモデルの重みをロード\n","    model.load_state_dict(torch.load(model_save_path, map_location='cpu'))\n","    model.eval() # 評価用モードに変更\n","\n","    # テスト評価\n","    iou = smp_metrics.IoU(threshold=0.5)\n","    test_iou = test_loop(model, test_loader, iou, device)\n","\n","    print(np.mean(test_iou))\n","    test_iou_list.append(test_iou)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":226,"status":"ok","timestamp":1704448676841,"user":{"displayName":"髙木優介","userId":"16066762327054986394"},"user_tz":-540},"id":"axqTrG5ofGrI","outputId":"ba99fec7-7b16-47e7-eb9c-0d0105ab1a9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9288006006316653\n"]}],"source":["# IoUの平均をみる\n","print(np.array(test_iou_list).mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rL9QG_aazyCT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCVRMn0w8Yty"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMQ/YW5OiWYB50EtvUe25ym","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
